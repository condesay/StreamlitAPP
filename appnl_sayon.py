# -*- coding: utf-8 -*-
"""AppNL_Sayon.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bY4JF7g3PDYX_cBfdY-8q8agdb1dnC2f

<br>
Description<br>
Application NLP traitant:<br>
+ Tokenization & Lemmatization utilisant Spacy<br>
+ Named Entity Recognition(NER) utilisant SpaCy<br>
+ Sentiment Analysis utilisant TextBlob<br>
+ Document/Text Resu,é utilisant Gensim/Sumy<br>
Construit avec  Streamlit Framework, un très bon framework pour les projets ML and NLP avec peu de codes et facile à comprendre.<br>

Probleme à resoudre:
Gensim summarization et sentiment analysis donné directement positif ou negatif aulieu de polarité et subjectivité
"""

!pip install streamlit
import os
import re

!apt-get -qq install streamlit
!import streamlit as st

"""NLP Pkgs

Sumy Summary Pkg
"""

!pip install sumy
from sumy.parsers.plaintext import PlaintextParser
from sumy.nlp.tokenizers import Tokenizer
from sumy.summarizers.lex_rank import LexRankSummarizer

import nltk
nltk.download('punkt')
nltk.download('stopwords')

"""Function for Sumy Summarization"""

# Commented out IPython magic to ensure Python compatibility.
# 
# %%writefile app.py
# # Core Pkgs
# import streamlit as st
# import os
# import re
# 
# # NLP Pkgs
# from textblob import TextBlob
# import spacy
# from gensim.summarization.summarizer import summarize
# import nltk
# nltk.download('punkt')
# 
# # Sumy Summary Pkg
# from sumy.parsers.plaintext import PlaintextParser
# from sumy.nlp.tokenizers import Tokenizer
# from sumy.summarizers.lex_rank import LexRankSummarizer
# # function gensim summarization
# def summarize(doc):
#    doc = re.sub(r'\n|\r', ' ', doc)
#    doc = re.sub(r' +', ' ', doc)
#    doc = doc.strip()
#    result_gen= " ".join(doc.split()[:int(len(doc.split())/2)])
#    return result_gen
# # Function for Sumy Summarization
# def sumy_summarizer(docx):
# 	parser = PlaintextParser.from_string(docx,Tokenizer("english"))
# 	lex_summarizer = LexRankSummarizer()
# 	summary = lex_summarizer(parser.document,3)
# 	summary_list = [str(sentence) for sentence in summary]
# 	result = ' '.join(summary_list)
# 	return result
# 
# # Function to Analyse Tokens and Lemma
# @st.cache
# def text_analyzer(my_text):
# 	nlp = spacy.load('en_core_web_sm')
# 	docx = nlp(my_text)
# 	# tokens = [ token.text for token in docx]
# 	allData = [('"Token":{},\n"Lemma":{}'.format(token.text,token.lemma_))for token in docx ]
# 	return allData
# 
# # Function For Extracting Entities
# @st.cache
# def entity_analyzer(my_text):
# 	nlp = spacy.load('en_core_web_sm')
# 	docx = nlp(my_text)
# 	tokens = [ token.text for token in docx]
# 	entities = [(entity.text,entity.label_)for entity in docx.ents]
# 	allData = ['"Token":{},\n"Entities":{}'.format(tokens,entities)]
# 	return allData
# 
# # Enlever les caractères spéciaux , ponctuations
# def remove_special_characters(Description):
#     # define the pattern to keep
#     pat = r'[^a-zA-z0-9.,/:;\"\'\s]' 
#     return re.sub(pat, '', Description)
# 
# def main():
# 	""" NLP Application sur Streamlit """
# 
# 	# Title
# 	st.title(" NLP Application")
# 	st.subheader("Natural Language Processing Application")
# 	st.markdown("""
#     	#### Description
#     	+ C'est une application de Natural Language Processing(NLP) Basée sur du traitement du language Naturel, entre autres nous avons: 
#     	Tokenization , Lemmatization, Reconnaissance d'entités de nom (NER), Analyse de Sentiments ,  Résumé de texte...! 
#     	""")
#   
# 	# Summarization
# 	if st.checkbox("Trouvez le Résumé de votre texte"):
# 		st.subheader("Résumez votre Texte")
# 
# 		message = st.text_area("Entrez le Texte à résumer","Tapez Ici...")
# 		summary_options = st.selectbox("choisir méthode",['sumy','gensim'])
# 		if st.button("Summarize"):
# 			if summary_options == 'sumy':
# 				st.text("Utilisant la méthode Sumy ..")
# 				summary_result = sumy_summarizer(message)
# 			elif summary_options == 'gensim':
# 				st.text("Utilisant la méthode Gensim  ..")
# 				summary_result = summarize(message)
# 			else:
# 				st.warning("Using Default Summarizer")
# 				st.text("Utilisant la méthode Gensim  ..")
# 				summary_result = summarize(message)
# 			st.success(summary_result)
#   
# 	# Sentiment Analysis
# 	if st.checkbox("Trouvez le Sentiment votre  texte"):
# 		st.subheader("Identification du Sentiment dans votre Texte")
# 
# 		message = st.text_area("Entrez le Texte à identifier","Tapez Ici...")
# 		if st.button("Analyse"):
# 			blob = TextBlob(message)
# 			result_sentiment = blob.sentiment
# 			st.success(result_sentiment)
# 
# 	# Entity Extraction
# 	if st.checkbox("Trouvez les  Entités de noms dans votre texte"):
# 		st.subheader("Identification des Entités dans votre texte")
# 
# 		message = st.text_area("Entrez le Texte pour extraire NER","Tapez Ici...")
# 		if st.button("Extraction"):
# 			entity_result = entity_analyzer(message)
# 			st.json(entity_result)
# 
# 	# Tokenization 
# 	if st.checkbox("Trouvez les Tokens and Lemma du texte"):
# 		st.subheader("Tokenisez votre Texte")
# 
# 		message = st.text_area("Entrez le Texte à Tokeniser","Tapez Ici...")
# 		if st.button("Tokenise"):
# 			nlp_result = text_analyzer(message)
# 			st.json(nlp_result)
# 			
#  	# Translate 
# 	if st.checkbox("Trouvez la Traduction du  texte en Anglais"):
# 		st.subheader("Traduisez votre Texte")
# 
# 		message = st.text_area("Entrez le Texte à traduire","Tapez Ici...")
# 		if st.button("Traduction"):
# 		  
# 			traduction = TextBlob(message).translate(from_lang="fr",to="en")
# 			st.success(traduction)
#       
# 
# 	st.sidebar.subheader("Information sur  de l'Application de Bases de connaissances")
# 	st.sidebar.text("BDC (Bases De Connaissances) Application.")
# 	st.sidebar.info("Cette Application permet de trouver le sentiment score, les tokens et les lemmas dans une phrase ou texte, les entités de noms, suppressions des caractères sspéciaux et Resumé  du texte.!")
# 	
# 
# if __name__ == '__main__':
# 	main()
# 
#

!npm install localtunnel



"""Function to Analyse Tokens and Lemma"""

!streamlit run /content/app.py &>/content/logs.txt &

!npx localtunnel --port 8501